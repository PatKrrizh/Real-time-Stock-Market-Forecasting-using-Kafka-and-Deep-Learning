{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import json\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from kafka.structs import TopicPartition\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages to Kafka Server\n",
    "topic = 'Enter Topic Name'\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "producer = KafkaProducer(bootstrap_servers=bootstrap_servers, value_serializer=lambda x:json.dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Find last TimeStamp for which data is already uploaded to Kfaka server\n",
    "\"\"\"\n",
    "\n",
    "# initialize last timestamp with a required starting value\n",
    "last_timestamp=datetime.strptime('2021-01-01 00:00:00', \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# retrieve last time stamp from file if exists for given topic\n",
    "if os.path.isfile(topic+'_timestamp.txt'):\n",
    "    file = open(topic+\"_timestamp.txt\", \"r\") \n",
    "    last_timestamp=datetime.strptime(file.read(), \"%Y-%m-%d %H:%M:%S\")\n",
    "else:\n",
    "    # if file does not exists then find it from Kafka server data already uploaded using Kafka consumer for all partitions\n",
    "    # maintain offset for all partitions so that every time we don't have to start from first position\n",
    "    consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers, group_id='test',\n",
    "        consumer_timeout_ms=2000,\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "    partitions=consumer.partitions_for_topic(topic=topic)\n",
    "    # iterate through all partitions of the topic to get last time stamp\n",
    "    for p in partitions:\n",
    "        print(topic + ' -> ' + str(p))\n",
    "        offset=0\n",
    "        if os.path.isfile(topic+'_offset_'+str(p)+'.txt'):\n",
    "            # retrieve offset stored in file if exists set offset for the topic & partition\n",
    "            file = open(topic+'_offset_'+str(p)+'.txt', \"r\") \n",
    "            offset=int(file.read())\n",
    "        consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers, group_id='test',\n",
    "            consumer_timeout_ms=2000,\n",
    "            value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "        tp = TopicPartition(topic=topic, partition=p)\n",
    "        consumer.assign([tp])\n",
    "        consumer.seek(tp, offset)   # you can set the offset you want to resume from.\n",
    "        last_dt={}\n",
    "        new_offset=0\n",
    "        for msg in consumer:\n",
    "            # the msg begins with the offset you set\n",
    "            last_dt=msg.value\n",
    "            rec_date=datetime.strptime(list(last_dt.keys())[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "            if  rec_date > last_timestamp:\n",
    "                    last_timestamp=rec_date\n",
    "            new_offset=new_offset+1\n",
    "        # store new offset in file so that only few records are required to process to get last TimeStamp\n",
    "        file=open(topic+'_offset_'+str(p)+'.txt','w')\n",
    "        if new_offset-5 >= 0:\n",
    "            new_offset=new_offset-5\n",
    "        else:\n",
    "            new_offset=0\n",
    "        file.write(str(new_offset))\n",
    "        file.close()\n",
    "\n",
    "file=open(topic+'_timestamp.txt','w')\n",
    "file.write(str(last_timestamp))\n",
    "file.close()\n",
    "print(last_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recursively goes through the Alpha Vantage API stock data after waiting for 5 minutes\n",
    "Upload new data arrived using AV API & updating recording TimeStamp\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "# Define key & TimeSeries object to pull stock data using Alpha Vantage API\n",
    "key = 'Enter API Key'\n",
    "ts = TimeSeries(key, output_format='json')\n",
    "while True:\n",
    "    try:\n",
    "        # get data using get_intraday function of AV API\n",
    "        data, meta = ts.get_intraday('MSFT', interval='1min', outputsize='full')\n",
    "\n",
    "        # set stock data in chronological order\n",
    "        lst=sorted(data)\n",
    "        data2={}\n",
    "        for l in lst:\n",
    "            data2[l]=data[l]\n",
    "        # send data to Kafka server for which data point data is not sent\n",
    "        for key in data2:\n",
    "            rec_date=datetime.strptime(key, \"%Y-%m-%d %H:%M:%S\")\n",
    "            print(rec_date)\n",
    "            if rec_date > last_timestamp:\n",
    "                dic={}\n",
    "                dic[key]=data[key]\n",
    "                producer.send(topic=topic, value=dic)\n",
    "                last_timestamp=rec_date\n",
    "                print(rec_date)\n",
    "        # updating last time stamp in related topic time stamp file\n",
    "        file=open(topic+'_timestamp.txt','w')\n",
    "        file.write(str(last_timestamp))\n",
    "        file.close()\n",
    "        time.sleep(300)\n",
    "    except Exception as e:\n",
    "        logging.warning('exception while pulling datapoints from API / sending data to Kafka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close Kafka producer & consumer objects used\n",
    "producer.close()\n",
    "consumer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
