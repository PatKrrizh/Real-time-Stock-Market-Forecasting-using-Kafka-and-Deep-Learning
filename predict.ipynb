{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "history_points = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "def csv_to_dataset(csv_path):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    data = data.drop(0, axis=0)\n",
    "\n",
    "    data = data.values\n",
    "\n",
    "    data_normaliser = preprocessing.MinMaxScaler()\n",
    "    data_normalised = data_normaliser.fit_transform(data)\n",
    "\n",
    "    # using the last {history_points} open close high low volume data points, predict the next open value\n",
    "    ohlcv_histories_normalised = np.array([data_normalised[i:i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.array([data_normalised[:, 0][i + history_points].copy() for i in range(len(data_normalised) - history_points)])\n",
    "    next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)\n",
    "\n",
    "    next_day_open_values = np.array([data[:, 0][i + history_points].copy() for i in range(len(data) - history_points)])\n",
    "    next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "    y_normaliser = preprocessing.MinMaxScaler()\n",
    "    y_normaliser.fit(next_day_open_values)\n",
    "\n",
    "    def calc_ema(values, time_period):\n",
    "        # https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp\n",
    "        sma = np.mean(values[:, 3])\n",
    "        ema_values = [sma]\n",
    "        k = 2 / (1 + time_period)\n",
    "        for i in range(len(his) - time_period, len(his)):\n",
    "            close = his[i][3]\n",
    "            ema_values.append(close * k + ema_values[-1] * (1 - k))\n",
    "        return ema_values[-1]\n",
    "\n",
    "    technical_indicators = []\n",
    "    for his in ohlcv_histories_normalised:\n",
    "        # note since we are using his[3] we are taking the SMA of the closing price\n",
    "        sma = np.mean(his[:, 3])\n",
    "        macd = calc_ema(his, 12) - calc_ema(his, 26)\n",
    "        technical_indicators.append(np.array([sma]))\n",
    "        # technical_indicators.append(np.array([sma,macd,]))\n",
    "\n",
    "    technical_indicators = np.array(technical_indicators)\n",
    "\n",
    "    tech_ind_scaler = preprocessing.MinMaxScaler()\n",
    "    technical_indicators_normalised = tech_ind_scaler.fit_transform(technical_indicators)\n",
    "\n",
    "    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0] == technical_indicators_normalised.shape[0]\n",
    "    return ohlcv_histories_normalised, technical_indicators_normalised, next_day_open_values_normalised, next_day_open_values, y_normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('technical_model.h5')\n",
    "\n",
    "ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y, y_normaliser = csv_to_dataset('Daily_data.csv')\n",
    "\n",
    "test_split = 0.9\n",
    "n = int(ohlcv_histories.shape[0] * test_split)\n",
    "\n",
    "ohlcv_train = ohlcv_histories[:n]\n",
    "tech_ind_train = technical_indicators[:n]\n",
    "y_train = next_day_open_values[:n]\n",
    "\n",
    "ohlcv_test = ohlcv_histories[n:]\n",
    "tech_ind_test = technical_indicators[n:]\n",
    "y_test = next_day_open_values[n:]\n",
    "\n",
    "unscaled_y_test = unscaled_y[n:]\n",
    "\n",
    "y_test_predicted = model.predict([ohlcv_test, tech_ind_test])\n",
    "y_test_predicted = y_normaliser.inverse_transform(y_test_predicted)\n",
    "\n",
    "buys = []\n",
    "sells = []\n",
    "thresh = 0.01\n",
    "\n",
    "start = 0\n",
    "end = -1\n",
    "\n",
    "x = -1\n",
    "i = 0\n",
    "for ohlcv, ind in zip(ohlcv_test[start:end], tech_ind_test[start:end]):\n",
    "    normalised_price_today = ohlcv[-1][0]\n",
    "    normalised_price_today = np.array([[normalised_price_today]])\n",
    "    price_today = y_normaliser.inverse_transform(normalised_price_today)\n",
    "    predicted_price_tomorrow = y_test_predicted[i]\n",
    "    i=i+1\n",
    "    delta = predicted_price_tomorrow - price_today\n",
    "    if delta > thresh:\n",
    "        buys.append((x, price_today[0][0]))\n",
    "    elif delta < -thresh:\n",
    "        sells.append((x, price_today[0][0]))\n",
    "    x += 1\n",
    "print(f\"buys: {len(buys)}\")\n",
    "print(f\"sells: {len(sells)}\")\n",
    "\n",
    "def compute_earnings(buys_, sells_):\n",
    "    purchase_amt = 100\n",
    "    stock = 0\n",
    "    balance = 0\n",
    "    while len(buys_) > 0 and len(sells_) > 0:\n",
    "        if buys_[0][0] < sells_[0][0]:\n",
    "            # time to buy $10 worth of stock\n",
    "            balance -= purchase_amt\n",
    "            stock += purchase_amt / buys_[0][1]\n",
    "            buys_.pop(0)\n",
    "        else:\n",
    "            # time to sell all of our stock\n",
    "            balance += stock * sells_[0][1]\n",
    "            stock = 0\n",
    "            sells_.pop(0)\n",
    "    print(f\"earnings: ${balance}\")\n",
    "\n",
    "\n",
    "# we create new lists so we dont modify the original\n",
    "compute_earnings([b for b in buys], [s for s in sells])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "\n",
    "real = plt.plot(unscaled_y_test[start:end], label='real')\n",
    "pred = plt.plot(y_test_predicted[start:end], label='predicted')\n",
    "\n",
    "if len(buys) > 0:\n",
    "    plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)\n",
    "if len(sells) > 0:\n",
    "    plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)\n",
    "\n",
    "# real = plt.plot(unscaled_y[start:end], label='real')\n",
    "# pred = plt.plot(y_predicted[start:end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
